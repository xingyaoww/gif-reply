import numpy as np
import torch
from ignite.metrics import Accuracy
from ignite.metrics import Average
from sklearn.metrics import dcg_score
from torch import nn
from tqdm import tqdm


class DCGMetric():
    """
    Run for validation.
    Will plot separate DCG score on train set and validation set
    using GIF feature generated by current feature.

    NOTE: gif_feature_path will only be used to fetch the entire list
    of GIF ids, its feature will NOT be used.
    """

    def __init__(
        self, inference_dataloader, train_dataloader, val_dataloader,
        batchsize=128, k=30,
    ):
        self.batchsize = batchsize
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        self.inference_dataloader = inference_dataloader

        # Internal feature map
        self.gif_id_to_feature = {}
        # k used to calculate DCG
        self.K = k

    def reset(self):
        # Not used
        pass

    def update(self, *args, **kwargs):
        # Not used
        pass

    @staticmethod
    def calculate_dcg(y_true_label: np.array, y_pred: np.array, y_score: np.array):
        assert len(y_true_label.shape) == 1
        assert len(y_pred.shape) == 2
        assert len(y_score.shape) == 2
        y_true_label = np.expand_dims(y_true_label, axis=1)
        y_true = (y_true_label == y_pred).astype(np.int8)
        # print(f"y_true: {y_true}\ny_pred:{y_pred}\ny_score:{y_score}")
        assert len(y_true.shape) >= 2
        assert len(y_pred.shape) >= 2
        return dcg_score(y_true, y_score)

    def cal_dcg_score_with_dataloader(self, model, gif_features, dataloader, gif_id_to_idx):
        all_y_scores = []
        all_y_preds = []
        all_gif_indices = []

        # Inference for similarity score
        for _, _data in tqdm(enumerate(dataloader), total=len(dataloader)):
            (tweet_input_ids, _, gif_ids), _ = _data
            tweet_input_ids = tweet_input_ids.cuda()
            tweet_features = model.extract_tweet_feature(tweet_input_ids)
            probs = model.calculate_score(
                tweet_features, gif_features, include_softmax=True,
            )

            y_score, y_pred = torch.topk(
                probs, k=self.K, dim=-1,
            )
            y_pred = y_pred.detach().cpu().numpy()
            y_score = y_score.detach().cpu().numpy()

            gif_indices = list(
                map(lambda gif_id: gif_id_to_idx[gif_id], gif_ids),
            )

            all_y_scores.append(y_score)
            all_y_preds.append(y_pred)
            all_gif_indices += gif_indices

        # Calculate DCG score
        all_y_preds = np.vstack(all_y_preds)
        all_y_scores = np.vstack(all_y_scores)
        all_gif_indices = np.array(all_gif_indices)

        dcg = self.calculate_dcg(
            y_true_label=all_gif_indices, y_pred=all_y_preds, y_score=all_y_scores,
        )
        return dcg

    def compute(self, model, train=False):
        results = {}

        # Only works in validation mode
        if train:
            return results

        model.eval()
        if isinstance(model, nn.DataParallel):
            model = model.module
        with torch.no_grad():
            # Generation of GIF features
            print(f'Starting generating GIF features using current model.')
            for i, _data in tqdm(enumerate(self.inference_dataloader), total=len(self.inference_dataloader)):
                gifs, gif_ids = _data
                gifs = [i.cuda() for i in gifs]
                features = model.extract_gif_feature(gifs).detach().cpu()
                for i, gif_id in enumerate(gif_ids):
                    self.gif_id_to_feature[gif_id] = features[i]
                del gifs
                del features

            # Generate Tensor form GIF feature
            gif_idx_to_id, gif_features = list(
                zip(*self.gif_id_to_feature.items()),
            )
            gif_features = torch.stack(gif_features)

            gif_id_to_idx = dict(zip(gif_idx_to_id, range(len(gif_idx_to_id))))
            gif_features = gif_features.cuda()
            print(f'GIF features shape: {gif_features.shape}')

            # Calculate DCG for train/dev
            print(f'Calculating DCG on training set using current model.')
            results['DCG-train'] = self.cal_dcg_score_with_dataloader(
                model, gif_features, self.train_dataloader, gif_id_to_idx,
            )
            print(f'Calculating DCG on validation set using current model.')
            results['DCG-val'] = self.cal_dcg_score_with_dataloader(
                model, gif_features, self.val_dataloader, gif_id_to_idx,
            )
        model.train()
        return results


class CLIPMetrics():
    def __init__(self, inference_dataloader, train_dataloader, val_dataloader, **kwargs):
        # Initialize all metrics
        self.metrics = {}
        self.metrics['loss'] = Average()
        self.metrics['accuracy'] = Accuracy()
        # NOTE: in the case of GIF-reply, IDCG always equals 1, hence DCG=NDCG
        self.metrics['dcg'] = DCGMetric(
            inference_dataloader, train_dataloader, val_dataloader,
        )

    def reset(self):
        """Reset internal metrics.
        """
        for key in self.metrics:
            self.metrics[key].reset()

    def update(self, loss, y_pred, y_true):
        """Update internal metrics

        Args:
            loss ([type]):
            y_pred ([type]):
            y_true ([type]):
        """
        self.metrics['loss'].update(loss.item())
        for key in self.metrics:
            if key == 'loss':
                continue
            self.metrics[key].update((y_pred, y_true))

    def compute(self, model, train=False, calculate_dcg=False, **kwargs):
        """Compute and return the metrics

        Returns:
            dict: a dict of metric results
        """
        result = {}
        if not train and calculate_dcg:
            assert model
            result.update(self.metrics['dcg'].compute(model, train=train))
        result['loss'] = self.metrics['loss'].compute().item()
        result['accuracy'] = self.metrics['accuracy'].compute()
        return result

    def log_tensorboard(
        self, writer, step, results=None, loss=None,
        model=None, train=True, calculate_dcg=False,
    ):
        """Compute and log the current metric to tensorboard.

        Args:
            writer ([type]): Writer for Tensorboard
            step ([type]): [description]
            loss ([float]): if not None, it will be the real time loss at `step`
            results ([dict]): if not None, it will be used as datasource to tensorboard,
                compute will not be called in this case.
            train (bool, optional): whether in training mode. Defaults to True.
        """
        results = self.compute(
            model, train=train, calculate_dcg=calculate_dcg,
        ) if results is None else results
        mode_str = 'train' if train else 'val'
        writer.add_scalar(
            'Loss/' + mode_str,
            results['loss'] if loss is None else loss.item(), step,
        )
        writer.add_scalar(
            'Accuracy/' + mode_str,
            results['accuracy'], step,
        )
        if 'DCG-train' in results:
            writer.add_scalar(
                'DCG/train',
                results['DCG-train'], step,
            )
            writer.add_scalar(
                'DCG/val',
                results['DCG-val'], step,
            )
        return results
